{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Chenxi Li (A16341810)\n",
    "- Jialong Guo (A15851883)\n",
    "- Gege Bei(A16356724)\n",
    "- Sikai Liang(A16839298)\n",
    "- Jinyi Zhao (A16315154)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "The criteria of whether a game is recommended or not has been quite subjective and confusing, therefore, the goal of our project is to create a relatively objective universal model to estimate the quality and popularity of a new game, and determine whether it is recommended or not. The data of the dataset represents multiple criterias of the games, and some of the data are categorical (boolean), including the supported systems and rating(positive/negative), and the rest of the data are statistical, which includes the total counts of user reviews, the positive ratios of the games, the initial and final prices of the games, and the discounts that were offered. We will be using the algorithms that were learned in class, and we will divide these data into a training set (validation set), and test set to create and train our model to fit as closely as possible to the dataset, and we will use this model to estimate a new game. Finally, the performance will be measured using the f1 score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Link to the dataset: https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam\n",
    "\n",
    "The dataset we use contains 21232 unique observations and 13 variables. The observation consists of product name, date released, support systems for games, rating, user reviews, price, discount, etc. The critical variables would be rating for games, user reviews, and price. They are stored as numerical data in different columns. \n",
    "\n",
    "Before making the algorithm models, we will do data cleaning first and briefly analyze the data, checking for missing or null values in the dataset, eliminating outliers or extreme values that would affect accuracy of our model and predictions, finding the dataset distribution and correlation between different variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Just like what we have mentioned above, the input of our data includes two major categories — categorical variables and statistical variables, hence our solution/model needs to include several algorithms in order to take both of these variables into account when deciding whether the game is recommended or not. We will be using one-hot encoding for the categorical variables(boolean), which means we will transform the data such as the supported system of the game. Then we will add the sum of the variables for each row, since each row represents a game. This will determine the games that are most adaptive, since the higher the sum is , the most systems it could be implemented on. Then, we will be using linear regression to tackle the statistical variable, which means we will use the linear regression to test the correlation between the rating scales and the ratio. The correlation will be acted like a decision boundary in order to determine the threshold of the positive ratio that could be classified as positive rated games(mostly positive, very positive etc.). Then we will create a model that combines these two algorithms, and the model would be a binary classification model, which means it could be used to determine whether a game is recommended or not. After creating the model, we will use a game that was not in the dataset and takes the specs of the games back into our model to test the accuracy. Moreover, the metric that we will be using is F1 score, which is a metric that is used to determine the performance of a binary classification model.\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation metric that we chose is the F1 score, as we learned in the class, the F1 score is used to evaluate the performance of a binary classification model, which fits our model(the intended solution) perfectly, since we are trying to generate a model that could classify either a game is good or not, and unlike other metrics, F1 scores takes both precision and recall into account, which means it is the most balanced metric among them. This is important in our case, since the false positives and false negatives are equally important. False positives in this case represents the game that is actually bad but is classified as a good game, which would increase the potential buyers of the game, and also increase the potential financial loss to the buyers since the game might not be worth buying; and the false negatives indicate that the game is actually a good game but the model classified it as a bad game, which would cause financial loss to the companies since less people would be buying the game. Therefore, the F1 score would be the best option since it could tell us how the model is performing based on these two factors(FN and FP). The mathematical representations of this metric is F1 = 2 * (precision * recall) / (precision + recall), and the metric is derived from the harmonic mean of precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All data used in this project are collected and stored through a publicly accessible way from Kaggle official users.\n",
    "2. All data will be only used for the purpose of this project, and will not be used for other private offended purposes. \n",
    "3. We will minimize the harmful consequences concerning any potential bias or impacting on any specific race group or individuals because we ensure that no particular \n",
    "   names or races or religion stuff will show in our data or project.\n",
    "4. Any potential conflict of interest will be disclosed and we tried to take special attention on the topics such as nationality, religion, or ethnicity. However, we \n",
    "   are going to analyze the game from different producers. But we will try to point out any arbitrary variables that will influence our predicting results and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* Have group meetings every week, make clear deadlines, and update the progress \n",
    "* Express opinions and listen actively to each other\n",
    "* Reach consensus that everyone agrees with\n",
    "* Ensure everyone contributing equally \n",
    "* Respect the diversity among culture, background, and personal beliefs\n",
    "* Properly illustrate the learning outcome from inner course material and individual study\n",
    "* Finish a project that makes everyone proud of\n",
    "* Always following the academic integrity rules set by both the department and the instructional team\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/20 |  7 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/21  | 7 PM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/22  | 7 PM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/28  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/7   | 6 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 6 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
